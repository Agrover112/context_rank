import csv 
import re 
import os 


import matchzoo as mz
print(mz.__version__)

task = mz.tasks.Ranking()
print(task)


import pandas as pd
bdf=pd.read_csv('DRL_dataset_200.csv') #This will be predefined in the user input any csv



def inputs(bdf,i):
  s=(bdf.iloc[i]['ttxt'])
  fs= open("temp.txt","w+")
  fs.write(s)
  fs=open('temp.txt',"r+")
  rd=fs.read()
  cleaned=clean(rd)
  return cleaned
  #text_file = open("sample.txt", "wt")
  #n = text_file.write(s)



def clean(txt):    
    import re, string
    #txt= open("uH3h7NAk.txt", "r+")
    #txt= open(fname, "r+")
    #txt=txt.read()#Reading
    txt=btxt
    print(txt)
    txt=str(txt.encode(encoding = 'UTF-8',errors = 'strict')) #UTF-8 Encoding
    clean = re.sub(r"[0-9,.;@#?/&%"",(),[],!&$]+\ *", " ", txt.replace('b',''))  #Removes unncessary stuff for word vectors
    print(clean)
    s=clean
    exclude = set(string.punctuation)
    table = str.maketrans("","")
    regex = re.compile('[%s]' % re.escape(string.punctuation)) #Punctuations
    text= regex.sub('', s)
    import nltk
    #nltk.download('stopwords')
    from nltk.corpus import stopwords  #Stop Words influencing the game
    cachedStopWords = stopwords.words("english")
    text = '  '.join([word for word in text.split() if word not in cachedStopWords]).lower()
    return text


#Sends the dataframe here and parses for each documnet contained in iloc[0,1,2....n]
for i in range(len(bdf)):
  res=inputs(bdf,i)
  print(res)







train_raw = mz.datasets.toy.load_data(stage='train', task=task)
test_raw = mz.datasets.toy.load_data(stage='test', task=task)


type(train_raw)

train_raw.left.head()

train_raw.right.head()

train_raw.relation.head()

train_raw.frame().head()

preprocessor = mz.preprocessors.BasicPreprocessor()

preprocessor.fit(train_raw)

preprocessor.context


train_processed = preprocessor.transform(train_raw)
test_processed = preprocessor.transform(test_raw)


train_processed.left.head()



vocab_unit = preprocessor.context['vocab_unit']
print('Orig Text:', train_processed.left.loc['Q1']['text_left'])
sequence = train_processed.left.loc['Q1']['text_left']
print('Transformed Indices:', sequence)
print('Transformed Indices Meaning:',
      '_'.join([vocab_unit.state['index_term'][i] for i in sequence]))



mz.models.list_available()


model = mz.models.DenseBaseline()


print(model.params)

model.params.to_frame()[['Name', 'Description', 'Value']]

model.params['task'] = task
model.params['mlp_num_units'] = 3
print(model.params)


model.params.update(preprocessor.context)



model.params.completed()



model.build()
model.compile()


model.backend.summary()




x, y = train_processed.unpack()
test_x, test_y = test_processed.unpack()

model.fit(x, y, batch_size=32, epochs=5)



data_generator = mz.DataGenerator(train_processed, batch_size=32)


model.fit_generator(data_generator, epochs=5, use_multiprocessing=True, workers=4)





model.evaluate(test_x, test_y)

model.predict(test_x)


model.save('my-model')
